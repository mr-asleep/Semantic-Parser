FeatureVector.ignoreZeroWeight < bool> : When logging, ignore features with zero weight [false]
FeatureVector.logFeaturesLimit <  int> : Log only this number of top and bottom features [2147483647]
LambdaCalculusConverter.inPath <  str> : Input path (lambda calculus) [overnight/geo/geosents280-typed.ccg.test.new]
LambdaCalculusConverter.specPath <  str> : Specification of translations [overnight/geo/geo.spec]
LambdaCalculusConverter.varPath <  str> : Specification of variable names [overnight/geo/geo.vars]
LambdaCalculusConverter.primPath <  str> : Specification of primitive types [overnight/geo/geo.primitives]
LambdaCalculusConverter.replacePath <  str> : Specification of formula replacements [overnight/geo/geo.replace]
LambdaCalculusConverter.manualConversionsPath <  str> : Specification of manual conversions [overnight/geo/geo.manual_conversions]
LambdaCalculusConverter.outPath <  str> : Output path (examples) [overnight/geo/geo.out.json]
LambdaCalculusConverter.runInd <  int> : Specific example to parse and run [-1]
LambdaCalculusConverter.lexiconPath <  str> : Output path for lexicon grammar [overnight/geo/geo.out.grammar]
LambdaCalculusConverter.verbose < bool> : Verbose output (for debugging) [false]
FloatingParser.defaultIsFloating < bool> : Whether rules without the (anchored 1) or (floating 1) tag should be anchored or floating [true]
FloatingParser.maxDepth        <  int> : Limit on formula depth (or formula size when --useSizeInsteadOfDepth is true) [10]
FloatingParser.useSizeInsteadOfDepth < bool> : Put a limit on formula size instead of formula depth [false]
FloatingParser.consecutiveRules < bool> : Whether floating rules are allowed to be applied consecutively [true]
FloatingParser.initialFloatingHasZeroDepth < bool> : Whether floating rule (rule $A (a)) should have depth 0 or 1 [false]
FloatingParser.filterChildDerivations < bool> : Filter child derivations using the type information from SemanticFn [true]
FloatingParser.useAnchorsOnce  < bool> : Whether anchored spans/tokens can only be used once in a derivation [false]
FloatingParser.useMaxAnchors   <  int> : Each span can be anchored this number of times (unused if useAnchorsOnce is active) [-1]
FloatingParser.executeAllDerivations < bool> : Whether to always execute the derivation [false]
FloatingParser.printPredictedUtterances < bool> : Whether to output a file with all utterances predicted [false]
FloatingParser.trainBeamSize   <  int> : Custom beam size at training time (default = Parser.beamSize) [-1]
FloatingParser.betaReduce      < bool> : Whether to beta reduce the formula [false]
FloatingParser.summarizeRuleTime < bool> : DEBUG: Print amount of time spent on each rule [false]
FloatingParser.maxFloatingParsingTime <  int> : Stop the parser if it has used more than this amount of time (in seconds) [2147483647]
ParserState.customExpectedCounts < enum> : Use a custom distribution for computing expected counts [NONE] NONE|UNIFORM|TOP|TOPALT|RANDOM
ParserState.contrastiveMargin  <  dbl> : For customExpectedCounts = TOP, only update if good < bad + margin [1000000.0]
ParserState.pruneByProbDiff    < bool> : Whether to prune based on probability difference [false]
ParserState.probDiffPruningThresh <  dbl> : Difference in probability for pruning by prob diff [100.0]
ParserState.throwFeaturesAway  < bool> : Throw features away after scoring to save memory [false]
Server.port                    <  int> :  [8400]
Server.numThreads              <  int> :  [4]
Server.title                   <  str> :  [SEMPRE Demo]
Server.headerPath              <  str> :  []
Server.basePath                <  str> :  [demo-www]
Server.verbose                 <  int> :  [1]
Server.htmlVerbose             <  int> :  [1]
Builder.inParamsPath           <  str> :  []
Builder.executor               <  str> :  [freebase.SparqlExecutor]
Builder.valueEvaluator         <  str> :  [ExactValueEvaluator]
Builder.parser                 <  str> :  [BeamParser]
CatSizeBound.verbose           <  int> : verbosity [0]
Lexicon.cachePath              <  str> : The path for the cache []
LexiconFn.maxEntityEntries     <  int> : Number of entities to return from entity lexicon [100]
LexiconFn.maxUnaryEntries      <  int> :  [2147483647]
LexiconFn.maxBinaryEntries     <  int> :  [2147483647]
LexiconFn.verbose              <  int> : Verbose [0]
LexiconFn.lexiconClassName     <  str> : Class name for lexicon []
LexiconFn.useHistogramFeatures < bool> :  [true]
MergeFn.hardTypeCheck          < bool> : whether to do a hard type-check [true]
MergeFn.showTypeCheckFailures  < bool> :  [false]
MergeFn.verbose                <  int> : Verbose [0]
TypeInference.verbose          <  int> : Verbosity level [1]
TypeInference.typeLookup       <  str> : Class for looking up types [NullTypeLookup]
BinaryLexicon.maxEntries       <  int> : Number of results return by the lexicon [1000]
BinaryLexicon.binaryLexiconFilesPath <  str> : Path to binary lexicon files [/dev/null]
BinaryLexicon.verbose          <  int> : Verbosity [0]
BinaryLexicon.keyToSortBy      <  str> : Alignment score to sort by [Intersection_size_typed]
FreebaseTypeLookup.entityTypesPath <  str> : Cache path to the types path []
BeamParser.maxNewTreesPerSpan  <  int> :  [2147483647]
MixParser.verbose              <  int> : verbosity [1]
MixParser.parsers              <  unk> : list of parsers to use along with options []
LanguageAnalyzer.languageAnalyzer <  str> :  [SimpleAnalyzer]
LanguageAnalyzer.lowerCaseTokens < bool> : Whether to convert tokens in the utterance to lowercase [true]
BridgeFn.verbose               <  int> : Verbose [0]
BridgeFn.useBinaryPredicateFeatures < bool> : Whether to have binary predicate features (ovrefits on small data) [true]
BridgeFn.filterBadDomain       < bool> : Whether to filter bad domains such as user and common [true]
JoinFn.verbose                 <  int> : Verbose [0]
JoinFn.showTypeCheckFailures   < bool> :  [false]
JoinFn.typeInference           < bool> :  [true]
JoinFn.specializedTypeCheck    < bool> :  [false]
TargetValuePreprocessor.targetValuePreprocessor <  str> :  []
Params.defaultWeight           <  dbl> : By default, all features have this weight [0.0]
Params.initWeightsRandomly     < bool> : Randomly initialize the weights [false]
Params.initRandom              < rand> : Randomly initialize the weights [1]
Params.initStepSize            <  dbl> : Initial step size [1.0]
Params.stepSizeReduction       <  dbl> : How fast to reduce the step size [0.0]
Params.adaptiveStepSize        < bool> : Use the AdaGrad algorithm (different step size for each coordinate) [true]
Params.dualAveraging           < bool> : Use dual averaging [false]
Params.l1Reg                   <  str> : Whether to do lazy l1 reg updates [none]
Params.l1RegCoeff              <  dbl> : L1 reg coefficient [0.0]
Params.lazyL1FullUpdateFreq    <  int> : Lazy L1 full update frequency [5000]
Parser.printAllPredictions     < bool> : For debugging, whether to print out all the predicted derivations [false]
Parser.maxPrintedPredictions   <  int> : Maximal number of predictions to print [2147483647]
Parser.maxPrintedTrue          <  int> : Maximal number of correct predictions to print [2147483647]
Parser.coarsePrune             < bool> : Use a coarse pass to prune the chart before full parsing [true]
Parser.verbose                 <  int> : How much output to print [0]
Parser.executeTopFormulaOnly   < bool> : Execute only top formula to be cheap (hack at test time for fast demo) [false]
Parser.visualizeChartFilling   < bool> : Whether to output chart filling visualization (huge file!) [false]
Parser.beamSize                <  int> : Keep this number of derivations per cell (exact use depends on the parser) [200]
Parser.partialReward           < bool> : Whether to update based on partial reward (for learning) [true]
Parser.unrollStream            < bool> : Whether to unroll derivation streams (applies to lazy parsers) [false]
Parser.derivationScoreNoise    <  dbl> : Inject random noise into the score (to mix things up a bit) [0.0]
Parser.derivationScoreRandom   < rand> : Source of random noise [1]
Parser.pruneErrorValues        < bool> : Prune away error denotations [false]
Parser.dumpAllFeatures         < bool> : Dump all features (for debugging) [false]
Parser.callSetEvaluation       < bool> : Call SetEvaluation during parsing [true]
SparqlExecutor.maxResults      <  int> : Maximum number of results to return [10]
SparqlExecutor.connectTimeoutMs <  int> : Milliseconds to wait until opening connection times out [60000]
SparqlExecutor.readTimeoutMs   <  int> : Milliseconds to wait until reading connection times out [60000]
SparqlExecutor.cachePath       <  str> : Save all SPARQL queries in a file so we don't have to hit the SPARQL endpoint too often []
SparqlExecutor.endpointUrl     <  str> : URL where the SPARQL server lives [http://localhost:3001/sparql]
SparqlExecutor.returnTable     < bool> : Whether to return a table of results rather than a list of entities (needed to support 'capital of each state') [false]
SparqlExecutor.lambdaAllowDiagonals < bool> : If false, then enforce that denotation of (lambda x (border x)) does not contain (x,x) [true]
SparqlExecutor.includeEntityNames < bool> : Whether to include entity names (mostly for readability) [true]
SparqlExecutor.includeSupportingInfo < bool> : Whether to return supporting information (e.g., 'length' for the 'longest river') [false]
SparqlExecutor.verbose         <  int> :  [10]
TokenLevelMatchFeatures.verbose <  int> : Verbose [0]
SimpleLexiconFn.maxEntityEntries <  int> : Number of entities to return from entity lexicon [100]
SimpleLexiconFn.verbose        <  int> : Verbosity level [0]
exec.monitor                   < bool> : Whether to create a thread to monitor the status of this execution. [true]
exec.execDir                   <  str> : Directory to put all output files; if empty, use execPoolDir. [dbpedia/out/]
exec.execPoolDir               <  str> : Directory which contains all the executions. []
exec.overwriteExecDir          < bool> : Overwrite the contents of the execDir if it doesn't exist (e.g., when running a thunk). [false]
exec.printOptionsAndExit       < bool> : Simply print options and exit. [false]
exec.miscOptions               < str*> : Miscellaneous options (written to options.map and output.map, displayed in servlet); example: a=3 b=4 []
exec.addToView                 < str*> : Name of the view to add this execution to in the servlet (simply creates an addToView file). []
exec.charEncoding              <  str> : Character encoding []
exec.jarFiles                  < str*> : Name of jar files to load prior to execution.  This is so that when the JARs change underneath us, we don't crash. []
exec.startMainTrack            < bool> : Whether to wrap everything around a main() track [true]
EntityLexicon.verbose          <  int> : Verbosity [0]
EntityLexicon.maxEntries       <  int> : Number of results return by the lexicon [1000]
EntityLexicon.numOfDocs        <  int> : Number of documents queried from Lucene [10000]
EntityLexicon.exactMatchIndex  <  str> : Path to the exact match lucene index directory []
EntityLexicon.inexactMatchIndex <  str> : Path to the inexact match lucene index directory [lib/lucene/4.4/inexact]
EntityLexicon.mid2idPath       <  str> : Cache path to the mid-to-id path []
EntityLexicon.entityPopularityPath <  str> : Path to entity popularity file []
log.maxIndLevel                <  int> : Maximum indent level. [2147483647]
log.msPerLine                  <  int> : Maximum number of milliseconds between consecutive lines of output. [0]
log.file                       <  str> : File to write log. [dbpedia/out/log]
log.stdout                     < bool> : Whether to output to the console. [true]
log.note                       <  str> : Dummy placeholder for a comment []
log.maxPrintErrors             <  int> : Maximum number of errors (via error()) to print [10000]
log.maxPrintWarnings           <  int> : Maximum number of warnings (via warning()) to print [10000]
Derivation.showValues          < bool> : When printing derivations, to show values (could be quite verbose) [true]
Derivation.showFirstValue      < bool> : When printing derivations, to show the first value (ignored when showValues is set) [false]
Derivation.showTypes           < bool> : When printing derivations, to show types [true]
Derivation.showRules           < bool> : When printing derivations, to show rules [false]
Derivation.showUtterance       < bool> : When printing derivations, to show canonical utterance [false]
Derivation.showCat             < bool> : When printing derivations, show the category [false]
Derivation.showExecutions      < bool> : When executing, show formulae (for debugging) [false]
Derivation.derivComparator     <  str> : Pick the comparator used to sort derivations [ScoredDerivationComparator]
Derivation.anchoredBonus       <  dbl> : bonus score for being all anchored [0.0]
ReinforcementParser.efficientCoarsePrune < bool> : Whether to do coarse pruning [true]
ReinforcementParser.multiplicativeBonus <  dbl> : Whether to do importance sampling [1000.0]
ReinforcementParser.numOfSamplesPerExample <  int> : Number of samples [1]
ReinforcementParser.updateGradientForCorrectMovesOnly < bool> : Whether to update gradient only for correct moves [true]
ReinforcementParser.lowProb    <  dbl> : Low probability for which we don't unroll the stream [0.01]
ReinforcementParser.simulateNonRlObjective < bool> : Whether to simulate the log liklihood objective [false]
ReinforcementParser.alwaysUnroll < bool> : Whether to always unroll (even at test time) [false]
FeatureExtractor.featureDomains <  unk> : Set of feature domains to include [rule opCount constant whType span lemmaAndBinaries denotation lexAlign joinPos skipPos]
FeatureExtractor.featureComputers <  unk> : Set of feature computer classes to load [[DerivOpCountFeatureComputer]]
FeatureExtractor.disableDenotationFeatures < bool> : Disable denotation features [false]
FeatureExtractor.useAllFeatures < bool> : Use all possible features, regardless of what featureDomains says [false]
FeatureExtractor.maxBigramDistance <  int> : For bigram features in paraphrased utterances, maximum distance to consider [3]
FeatureExtractor.lexicalBigramParaphrase < bool> : Whether or not paraphrasing and bigram features should be lexicalized [true]
FreebaseSearch.connectTimeoutMs <  int> : Milliseconds to wait until opening connection times out [60000]
FreebaseSearch.readTimeoutMs   <  int> : Milliseconds to wait until reading connection times out [60000]
FreebaseSearch.apiKey          <  str> : API key (needed to get more access) []
FreebaseSearch.cachePath       <  str> : Save results of Freebase API search []
FuzzyMatchFn.verbose           <  int> :  [0]
DerivOpCountFeatureComputer.countBasicOnly < bool> : Count only basic categories and SemanticFns [true]
DefaultDerivationPruningComputer.allowCountOne < bool> : (for badSummarizerHead) allow count on sets of size 1 [false]
JavaExecutor.convertNumberValues < bool> : Whether to convert NumberValue to int/double [true]
JavaExecutor.printStackTrace   < bool> : Print stack trace on exception [false]
JavaExecutor.contextPrefix     <  str> : Formula in the grammar whose name startsWith contextPrefix is context sensitive [context:]
JavaExecutor.classPathPrefix   <  str> : Reduce verbosity by automatically appending, for example, edu.stanford.nlp.sempre to java calls []
TextToTextMatcher.verbose      <  int> : Verbose [0]
SelectFn.verbose               <  int> : Verbose [0]
Dataset.inPaths                <str2*> : Paths to read input files (format: <group>:<file>) [test:dbpedia/que.json]
Dataset.maxExamples            <str2*> : Maximum number of examples to read []
Dataset.trainFrac              <  dbl> : Fraction of trainExamples (from the beginning) to keep for training [1.0]
Dataset.devFrac                <  dbl> : Fraction of trainExamples (from the end) to keep for development [0.0]
Dataset.splitRandom            < rand> : Used to randomly divide training examples [1]
Dataset.splitDevFromTrain      < bool> : whether to split dev from train [true]
Dataset.maxTokens              <  int> : Only keep examples which have at most this number of tokens [2147483647]
Dataset.globalGraphPath        <  str> : Path to a knowledge graph that will be uploaded as global context []
SimpleLexicon.inPaths          <  unk> : Path to load lexicon files from [dbpedia/dbpedia.lexicon]
SimpleLexicon.matchSuffixTypes <  unk> : Types to allow suffix (last word) matche (for people names []
FreebaseInfo.schemaPath        <  str> : ttl file with schema information [lib/fb_data/93.exec/schema2.ttl]
Grammar.inPaths                <  unk> :  [dbpedia/dbpedia.grammar]
Grammar.tags                   <  unk> : Variables which are used to interpret the grammar file []
Grammar.binarizeRules          < bool> :  [true]
Grammar.useApplyFn             <  str> : Specifiy which ApplyFn to use: defaults to JoinFn when null []
SemTypeHierarchy.failOnUnknownTypes < bool> : Throw an error if the type is not registered in the type hierarchy. [false]
Learner.maxTrainIters          <  int> : Number of iterations to train [0]
Learner.batchSize              <  int> : When using mini-batch updates for SGD, this is the batch size [1]
Learner.outputPredDerivations  < bool> : Write predDerivations to examples file (huge) [false]
Learner.outputPredValues       < bool> : Write predicted values to a TSV file [false]
Learner.dumpFeaturesAndCompatibility < bool> : Dump all features and compatibility scores [false]
Learner.addFeedback            < bool> : Whether to add feedback [false]
Learner.sortOnFeedback         < bool> : Whether to sort on feedback [true]
Learner.verbose                <  int> : Verbosity [0]
Learner.initialization         <  unk> : Initialize with these parameters []
Learner.updateWeights          < bool> : Whether to update weights [true]
Learner.checkGradient          < bool> : Whether to check gradient [false]
Learner.skipUnnecessaryGroups  < bool> : Whether to skip the 'train' group in the last iteration and non-'train' groups in other iterations [false]
Learner.numParallelThreads     <  int> : Number of threads to parallelize [1]
Master.scriptPaths             <  unk> : Execute these commands before starting []
Master.commands                <  unk> : Execute these commands before starting (after scriptPaths) []
Master.logPath                 <  str> : Write a log of this session to this path []
Master.printHelp               < bool> : Print help on startup [true]
Master.contextMaxExchanges     <  int> : Number of exchanges to keep in the context [0]
Master.onlineLearnExamples     < bool> : Online update weights on new examples. [true]
Master.newExamplesPath         <  str> : Write out new examples to this directory []
Master.newParamsPath           <  str> : Write out new parameters to this directory []
Master.newGrammarPath          <  str> : Write out new grammar rules []
FreebaseValueEvaluator.useF1   < bool> : When evaluating lists, compute F1 rather than exact match [true]
UnaryLexicon.maxEntries        <  int> : Number of results return by the lexicon [1000]
UnaryLexicon.unaryLexiconFilePath <  str> : Path to unary lexicon file [/dev/null]
UnaryLexicon.unaryFilterThreshold <  int> : Threshold for filtering unaries [5]
UnaryLexicon.verbose           <  int> : Verbosity [0]
NumberFn.unitless              < bool> : Omit units [false]
NumberFn.alsoTestByConversion  < bool> : Also test numbers by try converting to float (instead of using NER tags) [false]
NumberFn.alsoTestByIsolatedNER < bool> : Also test numbers by applying NER on just the phrase [false]
NumberFn.allowedRange          <  unk> : range of allowed numbers. e.g. null: no limits, Lists.newArrayList(0,100): 0-100 inclusive []
SemanticFn.trackLocalChoices   < bool> : Whether or not to add to Derivation.localChoices during function application (for debugging only). [false]
DerivationPruner.pruningStrategies <  unk> : Pruning strategies to use []
DerivationPruner.pruningComputers <  unk> : DerivationPruningComputer subclasses to look for pruning strategies []
DerivationPruner.pruningVerbosity <  int> :  [0]
DerivationPruner.maxNumValues  <  int> : (for tooManyValues) maximum denotation size of the final formula [10]
WnExpander.verbose             <  int> : Verbose [0]
WnExpander.wnFile              <  str> : Path to Wordnet file [lib/wordnet-3.0-prolog]
WnExpander.wnRelations         <  unk> : Relations to expand with wordnet [[]]
Main.interactive               < bool> :  [true]
Main.server                    < bool> :  [false]
Main.masterType                <  str> :  [edu.stanford.nlp.sempre.Master]
Session.inParamsPath           <  str> :  []
